{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jZFEitwNMNuz-G98v5F9-eoXmXr0PzV-",
      "authorship_tag": "ABX9TyN0XpO32fCgp/5NN+wy5NL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marekhudec/MKA-MLF/blob/main/Final_Projekt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe9MP-2z8A5N"
      },
      "outputs": [],
      "source": [
        "# TRÉNOVACÍ MODEL\n",
        "# Načítanie knižníc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Výber zariadenia CPU alebo GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# definícia modelu CNN\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes, conv_channels=[16, 32, 64], kernel_sizes=[3, 3, 3], fc_sizes=[512]):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Vytvorenie konvolučných vrstiev\n",
        "        in_channels = 3\n",
        "        for out_channels, kernel_size in zip(conv_channels, kernel_sizes):\n",
        "            self.layers.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=kernel_size//2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "                )\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Vytvorenie flatten a fully-connected vrstiev\n",
        "        linear_layers = []\n",
        "        input_features = conv_channels[-1] * (64 // 2**len(conv_channels))**2\n",
        "        for output_features in fc_sizes:\n",
        "            linear_layers.append(nn.Linear(input_features, output_features))\n",
        "            linear_layers.append(nn.ReLU()) # Aktivačná funkcia\n",
        "            input_features = output_features\n",
        "        linear_layers.append(nn.Linear(input_features, num_classes))\n",
        "        self.fc = nn.Sequential(*linear_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definícia a načítanie datasetu\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = f\"{self.root_dir}/img_{idx + 1}.png\"\n",
        "        image = Image.open(img_name).convert('RGB') # konverzia na RGB\n",
        "        label = int(self.data_frame.iloc[idx, 1])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# načítanie štítkov\n",
        "labels_csv = r'C:\\Users\\Asus\\Desktop\\CNN\\y_train.csv'\n",
        "\n",
        "# načítanie priečinka s obrázkami + data augumentation\n",
        "image_root = r'C:\\Users\\Asus\\Desktop\\CNN\\train_data_unlabeled'\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# rozdelenie dát na trénovacie a validačné\n",
        "dataset = CustomDataset(csv_file=labels_csv, root_dir=image_root, transform=transform)\n",
        "train_size = 0.9\n",
        "train_indices, val_indices = train_test_split(list(range(len(dataset))), train_size=train_size, random_state=42)\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n"
      ],
      "metadata": {
        "id": "4js0GSbW3Ltr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definícia variabilných hyperparametrov\n",
        "hyperparameters = {\n",
        "    'lr': [0.01],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'optimizer': ['adam', 'sgd'],\n",
        "    'num_epochs': [4, 5, 6],\n",
        "    'conv_channels': [ (32, 64, 128)],\n",
        "    'kernel_sizes': [(3, 3, 3), (5, 3, 3)],\n",
        "    'fc_sizes': [(512,), (256, 128), (1024,)]\n",
        "}\n",
        "\n",
        "# Funkcia pre náhodný výber hyperparametrov\n",
        "def sample_hyperparameters(hyperparameters):\n",
        "    return {k: random.choice(v) for k, v in hyperparameters.items()}\n",
        "\n",
        "# definícia optimizéru Adama/SGD\n",
        "def get_optimizer(optimizer_name, parameters, lr):\n",
        "    if optimizer_name == 'adam':\n",
        "        return optim.Adam(parameters, lr=lr)\n",
        "    elif optimizer_name == 'sgd':\n",
        "        return optim.SGD(parameters, lr=lr, momentum=0.9)\n",
        "\n",
        "# Initialize plotting variables\n",
        "best_metrics = {\n",
        "    'train_loss': [],\n",
        "    'val_loss': [],\n",
        "    'accuracy': []\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "cXurWJCU3YR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementácia trénovacej slučky s použitím Random search algoritmu\n",
        "num_trials = 8\n",
        "best_accuracy = 0.87\n",
        "best_model = None\n",
        "best_params = None\n",
        "\n",
        "for trial in range(num_trials):\n",
        "    params = sample_hyperparameters(hyperparameters)\n",
        "    print(f\"Trial {trial+1}: Testing with parameters: {params}\")\n",
        "\n",
        "    model = CustomCNN(\n",
        "        num_classes=4,\n",
        "        conv_channels=params['conv_channels'],\n",
        "        kernel_sizes=params['kernel_sizes'],\n",
        "        fc_sizes=params['fc_sizes']\n",
        "    ).to(device)\n",
        "  # Loaderi pre data , nastavenie batch_size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "    optimizer = get_optimizer(params['optimizer'], model.parameters(), params['lr'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    # Training and validation loops\n",
        "    epoch_train_loss = []\n",
        "    epoch_val_loss = []\n",
        "    epoch_accuracy = []\n",
        "\n",
        "    for epoch in range(params['num_epochs']): # trénovací cyklus\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * images.size(0)\n",
        "        scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():# validačný cyklus\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader.dataset)\n",
        "        val_loss = total_val_loss / len(val_loader.dataset)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        epoch_train_loss.append(train_loss)\n",
        "        epoch_val_loss.append(val_loss)\n",
        "        epoch_accuracy.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{params['num_epochs']}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\") # výpis priebežných výsledkov poča epoch\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "        best_params = params\n",
        "        best_metrics['train_loss'] = epoch_train_loss\n",
        "        best_metrics['val_loss'] = epoch_val_loss\n",
        "        best_metrics['accuracy'] = epoch_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "I7205-Y-3lAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vykreslenie grafov\n",
        "epochs = range(1, len(best_metrics['train_loss']) + 1)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs, best_metrics['train_loss'], label='Training Loss')\n",
        "plt.plot(epochs, best_metrics['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, best_metrics['accuracy'], color='green', label='Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# uloženie najlepšieho výsledku modelu\n",
        "torch.save(best_model.state_dict(), 'best_custom_cnn_model.pth')\n",
        "print(f\"Best model saved with accuracy {best_accuracy:.2f}% and parameters {best_params}\")\n"
      ],
      "metadata": {
        "id": "MoEdoteY3n9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TESTOVACÍ MODEL\n",
        "# načítanie knižníc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# Testovací model s hodnotami najlepšieho výsledku trénovacieho modelu\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes, conv_channels=[32, 64, 128], kernel_sizes=[5, 3, 3], fc_sizes=[512]):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        in_channels = 3\n",
        "        for out_channels, kernel_size in zip(conv_channels, kernel_sizes):\n",
        "            self.layers.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1,\n",
        "                              padding=kernel_size // 2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "                )\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        linear_layers = []\n",
        "        input_features = conv_channels[-1] * (64 // 2 ** len(conv_channels)) ** 2\n",
        "        for output_features in fc_sizes:\n",
        "            linear_layers.append(nn.Linear(input_features, output_features))\n",
        "            linear_layers.append(nn.ReLU())\n",
        "            input_features = output_features\n",
        "        linear_layers.append(nn.Linear(input_features, num_classes))\n",
        "        self.fc = nn.Sequential(*linear_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Načítanie uloženého trénovacieho modelu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomCNN(num_classes=4).to(device)\n",
        "model_path = 'best_custom_cnn_model.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "# data augumentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Načítanie testovacích dát\n",
        "image_dir = r'C:\\Users\\Asus\\Desktop\\CNN\\test_data_unlabeled'\n",
        "\n",
        "results = []\n",
        "image_id = 0\n",
        "\n",
        "# testovanie obrázkov z testovacieho datasetu\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "        # Perform inference\n",
        "        with torch.no_grad():\n",
        "            output = model(image_tensor)\n",
        "            predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            \"id\": image_id,\n",
        "            \"target\": predicted_class\n",
        "        })\n",
        "        image_id += 1\n",
        "\n",
        "# Konverzia výsledkov do CSV\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('output_predictions.csv', index=False, columns=['id', 'target'])\n",
        "\n",
        "print(\"Finished processing and saved results to 'output_predictions.csv'\")\n"
      ],
      "metadata": {
        "id": "mUHAqgApFng6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}